{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4o8P7iuWTgZ",
        "outputId": "713dba0c-602c-472c-827d-042d2dfa8412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "from copy import deepcopy\n",
        "snowball = EnglishStemmer()\n",
        "from bs4 import BeautifulSoup\n",
        "import unicodedata\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "# from sklearn\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_ = pd.read_csv(\"sms_spam.csv\")"
      ],
      "metadata": {
        "id": "QtE_GGq8YbiL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_whitespace_and_special_chars(text):\n",
        "        \"\"\"general text cleaning\"\"\"\n",
        "        \"\"\"Includes removal of extra whitespace, special characters\"\"\"\n",
        "        \n",
        "        tab_newline_pattern = '[\\t\\n]'\n",
        "        multi_space = ' {2,}'\n",
        "        special_chars = '[^a-zA-Z0-9 ]'        \n",
        "        formatted_text = re.sub(tab_newline_pattern, ' ', text)\n",
        "        formatted_text = re.sub(multi_space, ' ', formatted_text)\n",
        "        formatted_text = re.sub(special_chars, ' ', formatted_text)\n",
        "        formatted_text = re.sub(multi_space, ' ', formatted_text)\n",
        "        return formatted_text\n",
        "def removeStopWord(s):\n",
        "        \"\"\" Removing English stopwords from the text \"\"\"\n",
        "        \n",
        "        stop = set(stopwords.words('english'))\n",
        "        return \" \".join([words for words in word_tokenize(s) if words not in stop])\n",
        "    \n",
        "def remove_non_ascii(text):\n",
        "        \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "        text = re.sub(r'\\x85', '', text) # replace ellipses\n",
        "        text = re.sub(r'\\x91', '', text)  # replace left single quote\n",
        "        text = re.sub(r'\\x92', '', text)  # replace right single quote\n",
        "        text = re.sub(u'\\x93', '', text)  # replace left double quote\n",
        "        text = re.sub(u'\\x94', '', text)  # replace right double quote\n",
        "        text = re.sub(r'\\x95', '', text)   # replace bullet\n",
        "        text = re.sub(r'\\x96', '', text)   # replace bullet\n",
        "        text = re.sub(r'\\x99', '', text)   #replace TM\n",
        "        text = re.sub(r'\\xae', '', text)    # replace (R)\n",
        "        text = re.sub(r'\\xb0', '', text)    # replace degree symbol\n",
        "        text = re.sub(r'\\xba', '', text)    # replace degree symbol\n",
        "        new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        return new_text    \n",
        "def snowball_stemmer(token):\n",
        "            return snowball.stem(token)\n",
        "def stemmer(text):\n",
        "        return \" \".join([snowball_stemmer(w) for w in text.split()]).strip()\n",
        "    \n",
        "def transform(x):\n",
        "        text = remove_non_ascii(x.lower())\n",
        "        text = remove_whitespace_and_special_chars(text)\n",
        "        text = removeStopWord(text)\n",
        "        # text = stemmer(text)\n",
        "        return text\n",
        "    "
      ],
      "metadata": {
        "id": "FX6M8dD_YjzC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_['text'] = data_['text'].apply(transform)\n"
      ],
      "metadata": {
        "id": "GiLxndbqYv2j"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_dict={\"spam\":0,\"ham\":1}\n",
        "data_['type'] = "
      ],
      "metadata": {
        "id": "FuQ6upx3vmea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_.to_csv(\"traning_data_3.csv\",index=False)"
      ],
      "metadata": {
        "id": "leNYkPslt5Oc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PqFwb4-Et3MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"traning_data_3.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Zs7YeFHVbjGt",
        "outputId": "35991609-7e78-4006-a1c6-576eabec170b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      type                                               text\n",
              "0      ham  go jurong point crazy available bugis n great ...\n",
              "1      ham                            ok lar joking wif u oni\n",
              "2     spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
              "3      ham                u dun say early hor u c already say\n",
              "4      ham             nah think goes usf lives around though\n",
              "...    ...                                                ...\n",
              "5569  spam  2nd time tried 2 contact u u 750 pound prize 2...\n",
              "5570   ham                        u b going esplanade fr home\n",
              "5571   ham                              pity mood suggestions\n",
              "5572   ham  guy bitching acted like interested buying some...\n",
              "5573   ham                                     rofl true name\n",
              "\n",
              "[5574 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71e788c6-8d81-4c18-976a-eb8167fff1b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah think goes usf lives around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>spam</td>\n",
              "      <td>2nd time tried 2 contact u u 750 pound prize 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>u b going esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>pity mood suggestions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>ham</td>\n",
              "      <td>guy bitching acted like interested buying some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5573</th>\n",
              "      <td>ham</td>\n",
              "      <td>rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71e788c6-8d81-4c18-976a-eb8167fff1b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71e788c6-8d81-4c18-976a-eb8167fff1b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71e788c6-8d81-4c18-976a-eb8167fff1b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# nlp library of Pytorch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import warnings as wrn\n",
        "wrn.filterwarnings('ignore')\n",
        "SEED = 2021\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cuda.deterministic = True\n"
      ],
      "metadata": {
        "id": "T0HhEyzQY1eH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
        "fields = [(\"type\",LABEL),('text',TEXT)]\n"
      ],
      "metadata": {
        "id": "_P2Y6vRAZh5F"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = data.TabularDataset(path=\"sms_spam.csv\",\n",
        "                                    format=\"csv\",\n",
        "                                    fields=fields,\n",
        "                                    skip_header=True\n",
        "                                   )\n",
        "\n",
        "print(vars(training_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk-Vin_abrKN",
        "outputId": "d8c110dd-a28c-49be-ac3e-c5665a4b7df2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'ham', 'text': ['Go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'Cine', 'there', 'got', 'amore', 'wat', '...']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# train and validation splitting\n",
        "train_data,valid_data = training_data.split(split_ratio=0.75,\n",
        "                                            random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "VcPCJneicL2u"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq=5)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "gv797CmacbhE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of text vocab:\",len(TEXT.vocab))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GibmB2cMcmX1",
        "outputId": "17952608-fed1-4059-ddab-26c1377b81b8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of text vocab: 1751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of label vocab:\",len(LABEL.vocab))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7rteFQzcrb5",
        "outputId": "d37d2270-45c3-48ef-cecf-5f30bd69c805"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of label vocab: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# We'll create iterators to get batches of data when we want to use them\n",
        "\"\"\"\n",
        "This BucketIterator batches the similar length of samples and reduces the need of \n",
        "padding tokens. This makes our future model more stable\n",
        "\n",
        "\"\"\"\n",
        "train_iterator,validation_iterator = data.BucketIterator.splits(\n",
        "    (train_data,valid_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # Sort key is how to sort the samples\n",
        "    sort_key = lambda x:len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "SlyAW3Svc2L-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,n_layers,bidirectional,dropout):\n",
        "        \n",
        "        super(LSTMNet,self).__init__()\n",
        "        \n",
        "        # Embedding layer converts integer sequences to vector sequences\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        \n",
        "        # LSTM layer process the vector sequences \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout,\n",
        "                            batch_first = True\n",
        "                           )\n",
        "        \n",
        "        # Dense layer to pr\n",
        "        self.fc = nn.Linear(hidden_dim * 2,output_dim)\n",
        "        # Prediction activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    \n",
        "    def forward(self,text,text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # Thanks to packing, LSTM don't see padding tokens \n",
        "        # and this makes our model better\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),batch_first=True)\n",
        "        \n",
        "        packed_output,(hidden_state,cell_state) = self.lstm(packed_embedded)\n",
        "        \n",
        "        # Concatenating the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "        \n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.sigmoid(dense_outputs)\n",
        "        \n",
        "        return outputs\n",
        "    \n"
      ],
      "metadata": {
        "id": "N8FDEQb8dOPq"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE_OF_VOCAB = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_HIDDEN_NODES = 64\n",
        "NUM_OUTPUT_NODES = 1\n",
        "NUM_LAYERS = 2\n",
        "BIDIRECTION = True\n",
        "DROPOUT = 0.2"
      ],
      "metadata": {
        "id": "pP9sKvwfopz4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMNet(SIZE_OF_VOCAB,\n",
        "                EMBEDDING_DIM,\n",
        "                NUM_HIDDEN_NODES,\n",
        "                NUM_OUTPUT_NODES,\n",
        "                NUM_LAYERS,\n",
        "                BIDIRECTION,\n",
        "                DROPOUT\n",
        "               )"
      ],
      "metadata": {
        "id": "PmX5iWGxq5R2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "criterion = nn.BCELoss()\n",
        "criterion = criterion.to(device)\n"
      ],
      "metadata": {
        "id": "g4hMRzAdrCZC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "rHXQC6nxrLm5"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # cleaning the cache of optimizer\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text,text_lengths = batch.text\n",
        "        \n",
        "        # forward propagation and squeezing\n",
        "        predictions = model(text,text_lengths).squeeze()\n",
        "        \n",
        "        # computing loss / backward propagation\n",
        "        loss = criterion(predictions,batch.type)\n",
        "        loss.backward()\n",
        "        \n",
        "        # accuracy\n",
        "        acc = binary_accuracy(predictions,batch.type)\n",
        "        \n",
        "        # updating params\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    # It'll return the means of loss and accuracy\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "eZfGCiHbrQxy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    # deactivate the dropouts\n",
        "    model.eval()\n",
        "    \n",
        "    # Sets require_grad flat False\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text,text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text,text_lengths).squeeze()\n",
        "              \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.type)\n",
        "            acc = binary_accuracy(predictions, batch.type)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "-JRPypTgrrVu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH_NUMBER = 15\n",
        "for epoch in range(1,EPOCH_NUMBER+1):\n",
        "    \n",
        "    train_loss,train_acc = train(model,train_iterator,optimizer,criterion)\n",
        "    \n",
        "    valid_loss,valid_acc = evaluate(model,validation_iterator,criterion)\n",
        "    \n",
        "    # Showing statistics\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHnHovklsA29",
        "outputId": "dc0d5075-4959-4e7f-8831-71880419abf1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.651 | Train Acc: 73.44%\n",
            "\t Val. Loss: 0.572 |  Val. Acc: 88.26%\n",
            "\n",
            "\tTrain Loss: 0.502 | Train Acc: 86.22%\n",
            "\t Val. Loss: 0.406 |  Val. Acc: 88.26%\n",
            "\n",
            "\tTrain Loss: 0.406 | Train Acc: 86.22%\n",
            "\t Val. Loss: 0.360 |  Val. Acc: 88.26%\n",
            "\n",
            "\tTrain Loss: 0.363 | Train Acc: 86.22%\n",
            "\t Val. Loss: 0.321 |  Val. Acc: 88.26%\n",
            "\n",
            "\tTrain Loss: 0.316 | Train Acc: 86.22%\n",
            "\t Val. Loss: 0.272 |  Val. Acc: 88.26%\n",
            "\n",
            "\tTrain Loss: 0.268 | Train Acc: 86.62%\n",
            "\t Val. Loss: 0.233 |  Val. Acc: 89.75%\n",
            "\n",
            "\tTrain Loss: 0.232 | Train Acc: 88.66%\n",
            "\t Val. Loss: 0.205 |  Val. Acc: 90.96%\n",
            "\n",
            "\tTrain Loss: 0.208 | Train Acc: 90.91%\n",
            "\t Val. Loss: 0.186 |  Val. Acc: 92.66%\n",
            "\n",
            "\tTrain Loss: 0.188 | Train Acc: 92.21%\n",
            "\t Val. Loss: 0.173 |  Val. Acc: 94.01%\n",
            "\n",
            "\tTrain Loss: 0.169 | Train Acc: 94.15%\n",
            "\t Val. Loss: 0.158 |  Val. Acc: 94.65%\n",
            "\n",
            "\tTrain Loss: 0.150 | Train Acc: 95.60%\n",
            "\t Val. Loss: 0.138 |  Val. Acc: 95.65%\n",
            "\n",
            "\tTrain Loss: 0.130 | Train Acc: 96.45%\n",
            "\t Val. Loss: 0.123 |  Val. Acc: 96.22%\n",
            "\n",
            "\tTrain Loss: 0.110 | Train Acc: 97.02%\n",
            "\t Val. Loss: 0.113 |  Val. Acc: 96.09%\n",
            "\n",
            "\tTrain Loss: 0.093 | Train Acc: 97.37%\n",
            "\t Val. Loss: 0.106 |  Val. Acc: 96.44%\n",
            "\n",
            "\tTrain Loss: 0.080 | Train Acc: 97.87%\n",
            "\t Val. Loss: 0.097 |  Val. Acc: 97.01%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5xy-qclsRc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}